Gradient descent:- It is a crucial optimization algorithm in machine learning used to minimize the cost function of a model.

a cost function quantifies the difference between a model's predicted values and the actual values.
It's a mathematical metric used to measure the model's performance and guide the optimization process.
By minimizing the cost function, the goal is to improve the model's accuracy and reduce prediction errors.



ElasticNet: 
Regularization: Combines L1 and L2 penalties to shrink coefficients and potentially eliminate less important features. 
Hyperparameters: Requires you to manually set alpha (the overall penalty strength) and l1_ratio (the proportion of L1 regularization). 
Model Selection: Does not automatically select the best hyperparameter values. 

ElasticNetCV: 
Regularization: Uses the same L1 and L2 regularization as ElasticNet. 
Hyperparameters: Automatically searches for the best alpha and l1_ratio using cross-validation. 
Model Selection: Selects the best-performing model based on the cross-validation results


Overfitting:
Overfitting occurs when a model becomes too complex and learns not only
the underlying patterns in the data but also the noise and irrelevant details.
This leads to high accuracy on the training data but poor performance on new data.

Regularization's Role:
Regularization techniques introduce a penalty to the loss function,
discouraging the model from learning overly complex relationships.
This penalty is typically based on the magnitude of the model's parameters (coefficients).

"cls" is used in the command prompt to clear the screen.

ASCII, short for American Standard Code for Information Interchange,
is a character encoding standard that represents text as numerical values.